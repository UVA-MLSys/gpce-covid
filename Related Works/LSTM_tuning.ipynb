{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LopEAYzbELVA"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j724k07rELVB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# disable chained assignments\n",
        "pd.options.mode.chained_assignment = None \n",
        "import os, gc\n",
        "import optuna, optuna_dashboard\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from datetime import datetime\n",
        "\n",
        "from models import *\n",
        "from utils import *\n",
        "from splits import *\n",
        "\n",
        "SEED = 7\n",
        "tf.random.set_seed(SEED)\n",
        "VERBOSE = 0\n",
        "Split = Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Result folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_folder = 'scratch/tuning_LSTM'\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emlXwxlMELVB"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s4ZnvkkJELVC",
        "outputId": "b7d0c71d-75d6-4308-ee80-89e029d2f68d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   FIPS  AgeDist  HealthDisp       Date  DiseaseSpread  Transmission  \\\n",
            "0  2261    0.014         8.8 2020-02-29            0.0           0.0   \n",
            "1  2261    0.014         8.8 2020-03-01            0.0           0.0   \n",
            "2  2261    0.014         8.8 2020-03-02            0.0           0.0   \n",
            "\n",
            "   VaccinationFull  SocialDist  Cases  TimeFromStart  SinWeekly  CosWeekly  \n",
            "0              0.0         0.5    0.0              0     -0.975     -0.223  \n",
            "1              0.0         0.5    0.0              1     -0.782      0.623  \n",
            "2              0.0         0.5    0.0              2      0.000      1.000  \n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('../TFT-pytorch/2022_May_cleaned/Top_100.csv')\n",
        "df['Date'] = pd.to_datetime(df['Date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    static_features = ['AgeDist', 'HealthDisp']\n",
        "    past_features = ['DiseaseSpread', 'Transmission', 'VaccinationFull', 'SocialDist']\n",
        "    known_future = ['SinWeekly', 'CosWeekly']\n",
        "    time_index = 'TimeFromStart' # note that this is an index feature commonly used by all timeseries models\n",
        "\n",
        "    features =  [time_index] + static_features + past_features + known_future\n",
        "    targets = ['Cases']\n",
        "    group_id = 'FIPS'\n",
        "    selected_columns = features + targets\n",
        "    input_sequence_length = 13\n",
        "    output_sequence_length = 15\n",
        "    batch_size = 64\n",
        "    buffer_size = 1000\n",
        "    epochs = 200\n",
        "    learning_rate = 1e-6\n",
        "    early_stopping_patience = 5\n",
        "    loss = 'mse'\n",
        "    n_trials = 25\n",
        "\n",
        "targets = Config.targets\n",
        "group_id = Config.group_id\n",
        "input_sequence_length = Config.input_sequence_length\n",
        "output_sequence_length = Config.output_sequence_length\n",
        "output_size = len(targets) * output_sequence_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gy6DE69ELVD"
      },
      "source": [
        "## Split and scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf0nwz_qELVD",
        "outputId": "23b9687e-e6fc-4867-eb5a-ea8412cf968d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: train (64000, 12), validation (3000, 12), test (3000, 12).\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df, test_df = split_data(df, Split, input_sequence_length)\n",
        "train_df, val_df, test_df, feature_scaler, target_scaler = scale_data(\n",
        "    train_df, val_df, test_df, Config.features, targets\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy_Jq3uSELVE"
      },
      "source": [
        "## Window generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, y_train = prepare_dataset(\n",
        "    train_df, Config, disable_progress_bar=(VERBOSE!=1)\n",
        ")\n",
        "x_val, y_val = prepare_dataset(\n",
        "    val_df, Config, disable_progress_bar=(VERBOSE!=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7Im3Z1QELVF"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOHTAa2eELVF"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(trial):\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
        "    hidden_size = trial.suggest_int(\"hidden_size\", 32, 128, step=16)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0, 0.3, step=0.1)\n",
        "    layers = trial.suggest_int(\"layers\", 2, 4, step=1)\n",
        "\n",
        "    model = build_LSTM(\n",
        "        x_train.shape[1:], output_size=output_size, loss=Config.loss, \n",
        "        hidden_size=hidden_size, dropout=dropout, \n",
        "        learning_rate=learning_rate, layers=layers\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def create_dataset(trial):\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "\n",
        "    train_data = cache_data(\n",
        "        x_train, y_train, batch_size=batch_size, \n",
        "        buffer_size=Config.buffer_size\n",
        "    )\n",
        "    val_data = cache_data(\n",
        "        x_val, y_val, batch_size=batch_size, \n",
        "    )\n",
        "    return train_data, val_data\n",
        "\n",
        "def objective(trial):\n",
        "    model = create_model(trial)\n",
        "    train_data, val_data = create_dataset(trial)\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        patience = Config.early_stopping_patience, \n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    model_checkpoint = ModelCheckpoint(\n",
        "        filepath=os.path.join(output_folder, 'model.h5'), \n",
        "        save_best_only=True, save_weights_only=True\n",
        "    )\n",
        "    model.fit(\n",
        "        train_data, validation_data=val_data,\n",
        "        epochs=Config.epochs,  \n",
        "        callbacks=[early_stopping, model_checkpoint],\n",
        "        verbose=VERBOSE\n",
        "    )\n",
        "    model.load_weights(model_checkpoint.filepath)\n",
        "    val_loss = model.evaluate(val_data, verbose=VERBOSE)\n",
        "\n",
        "    return val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-12-22 23:06:23,640]\u001b[0m Using an existing study with name 'LSTM' instead of creating a new one.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6c1df57315f4635b05ad253f2945634",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "958/958 [==============================] - 16s 14ms/step - loss: 0.7938 - val_loss: 0.7619\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.7619\n",
            "778/958 [=======================>......] - ETA: 2s - loss: 0.8770\u001b[32m[I 2022-12-22 23:06:40,760]\u001b[0m Trial 3 finished with value: 0.7618886828422546 and parameters: {'learning_rate': 0.0001647855359543581, 'hidden_size': 32, 'dropout': 0.0, 'layers': 2}. Best is trial 1 with value: 0.7436149716377258.\u001b[0m\n",
            "958/958 [==============================] - 19s 16ms/step - loss: 0.7895 - val_loss: 0.7289\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7289\n",
            "\u001b[32m[I 2022-12-22 23:06:43,910]\u001b[0m Trial 2 finished with value: 0.7288652062416077 and parameters: {'learning_rate': 5.4126009713509914e-05, 'hidden_size': 128, 'dropout': 0.3, 'layers': 3}. Best is trial 2 with value: 0.7288652062416077.\u001b[0m\n",
            "Number of finished trials:  4\n",
            "Best trial:\n",
            "  Value:  0.7288652062416077\n",
            "  Params: \n",
            "    dropout: 0.3\n",
            "    hidden_size: 128\n",
            "    layers: 3\n",
            "    learning_rate: 5.4126009713509914e-05\n"
          ]
        }
      ],
      "source": [
        "study_name = 'LSTM'\n",
        "storage_name = f\"sqlite:///{study_name}.db\"\n",
        "load_only = False\n",
        "\n",
        "if load_only:\n",
        "    study = optuna.load_study(\n",
        "        study_name=study_name, storage=storage_name\n",
        "    )\n",
        "else:\n",
        "    study = optuna.create_study(\n",
        "        study_name=study_name, storage=storage_name, direction='minimize', load_if_exists=True\n",
        "    )\n",
        "    study.optimize(\n",
        "        objective, n_trials=Config.n_trials, n_jobs=-1, \n",
        "        gc_after_trial=True, show_progress_bar=VERBOSE\n",
        "    )\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study)\n",
        "optuna.visualization.plot_param_importances(study)\n",
        "\n",
        "df = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\n",
        "df.round(6).to_csv(os.path.join(output_folder, 'trials.csv'), index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "43fc5fbfa959c1c54ddf7d7acab30a2019a504b895513ba1ba722e7f395657c0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

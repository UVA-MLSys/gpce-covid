{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jp_MQeY9Hob"
      },
      "source": [
        "# Introduction\n",
        "This file converts the cleaned raw dataset into a single merged file that the TFTModel can work on. The script version available at [prepare_data.py](../script/prepare_data.py).\n",
        "\n",
        "If you need to change the input feature set, only add that info in the `\"data\"` section of the json configuration  file. This notebook will update the rest (at least feature column mappings and locations) . If you have pivoted dynamic feature and need to melt that date columns, make sure to keep the feature name as `string` in `\"dynamic_features_map\"`. If it is already melted and your dynamic file has a `Date` column, `list` or `string` format both is fine.\n",
        "\n",
        "In the final output all null values are replaced with 0. If you don't want that, comment that out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI10VjY39Hof"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1M2WLI7D9Hog"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append( '..' )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fy3zL-09Hoh"
      },
      "source": [
        "# Setup storage\n",
        "\n",
        "You would need the `CovidMay17-2022` and `Support files` folders for the dateset. And the `TFT-pytorch` folder for the codes. Upload both of them in the place where you are running the code from. My folder structure looks like this\n",
        "* dataset_raw\n",
        "    * CovidMay17-2022\n",
        "    * Support files\n",
        "* TFT-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMX9mq7-9Hoi"
      },
      "source": [
        "## Googe drive\n",
        "Not needed, since you can run this on CPU. But set `running_on_colab = True` if using. Also update the `cd` path so that it points to the notebook folder in your drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "405O2njt9Hoi",
        "outputId": "06b68e92-5354-43ff-b93e-1e5b9502f15d"
      },
      "outputs": [],
      "source": [
        "running_on_colab = False\n",
        "\n",
        "if running_on_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    %cd /content/drive/My Drive/Projects/Covid/TFT-pytorch/notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlaIcaHc9Hoi"
      },
      "source": [
        "## Input\n",
        "If running on colab, modify the below paths accordingly. Note that this config.json is different from the config.json in TF2 folder as that is for the old dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kKXlhpDi9Hoj"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from Class.DataMerger import *\n",
        "\n",
        "@dataclass\n",
        "class args:\n",
        "    # folder where the cleaned feature file are at\n",
        "    dataPath = '../../dataset_raw/CovidMay17-2022'\n",
        "    supportPath = '../../dataset_raw/Support files'\n",
        "    configPath = '../config_2022_May.json'\n",
        "    cachePath = None # '../2022_Oct/Total.csv'\n",
        "\n",
        "    # choose this carefully\n",
        "    outputPath = '../2022_May_cleaned/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE7F4cXP9Hok",
        "outputId": "c5927406-1491-4ae3-d252-32e1f2f3f231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config file loaded from ../config_2022_Aug.json\n"
          ]
        }
      ],
      "source": [
        "# create output path if it doesn't exist\n",
        "if not os.path.exists(args.outputPath):\n",
        "    print(f'Creating output directory {args.outputPath}')\n",
        "    os.makedirs(args.outputPath, exist_ok=True)\n",
        "\n",
        "import json\n",
        "\n",
        "# load config file\n",
        "with open(args.configPath) as inputFile:\n",
        "    config = json.load(inputFile)\n",
        "    print(f'Config file loaded from {args.configPath}')\n",
        "    inputFile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BgfTz2F9Hol"
      },
      "source": [
        "# Data merger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VtM_7Mh9Hol"
      },
      "source": [
        "## Total features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get merger class\n",
        "dataMerger = DataMerger(config, args.dataPath, args.supportPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLrT8EfF9Hom",
        "outputId": "3a83f81f-7cc2-404e-a076-43372808dc0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique counties present 3142\n",
            "Merging feature Age Distribution.csv with length 3142\n",
            "Merging feature Health Disparities.csv with length 3142\n",
            "\n",
            "Merged static features have 3142 counties\n",
            "Will remove outliers from dynamic inputs.\n",
            "Will filter out dynamic features outside range, train start 2020-03-01 00:00:00 and test end 2022-08-04 00:00:00.\n",
            "Reading Disease Spread.csv\n",
            "Outliers found 5197, percent 0.186\n",
            "Min date 2020-02-28 00:00:00, max date 2022-08-04 00:00:00\n",
            "Length 2786954.\n",
            "\n",
            "Reading Transmissible Cases.csv\n",
            "Outliers found 584, percent 0.021\n",
            "Min date 2020-02-28 00:00:00, max date 2022-08-04 00:00:00\n",
            "Length 2786954.\n",
            "\n",
            "Reading Vaccination.csv\n",
            "Outliers found 194, percent 0.011\n",
            "Min date 2020-12-13 00:00:00, max date 2022-08-03 00:00:00\n",
            "Length 1798992.\n",
            "\n",
            "Reading Social Distancing.csv\n",
            "Outliers found 114319, percent 4.093\n",
            "Min date 2020-02-28 00:00:00, max date 2022-08-04 00:00:00\n",
            "Length 2786954.\n",
            "\n",
            "Total dynamic feature shape (2832710, 7)\n",
            "Will remove outliers from target.\n",
            "Will filter out target data outside range, train start 2020-03-01 00:00:00 and test end 2022-08-04 00:00:00.\n",
            "Reading Cases.csv\n",
            "Outliers found 97944, percent 3.377\n",
            "Setting negative daily Cases counts to zero.\n",
            "Min date 2020-01-22 00:00:00, max date 2022-08-02 00:00:00\n",
            "Length 2777528.\n",
            "\n",
            "Reading Deaths.csv\n",
            "Outliers found 202904, percent 6.997\n",
            "Setting negative daily Deaths counts to zero.\n",
            "Min date 2020-01-22 00:00:00, max date 2022-08-02 00:00:00\n",
            "Length 2777528.\n",
            "\n",
            "Total target feature shape (2777528, 4)\n",
            "Merging all features\n",
            "Total merged data shape (2786954, 11)\n",
            "Missing percentage in total data\n",
            "VaccinationFull    37.09\n",
            "Cases               0.34\n",
            "Deaths              0.34\n",
            "FIPS                0.00\n",
            "AgeDist             0.00\n",
            "HealthDisp          0.00\n",
            "Name                0.00\n",
            "Date                0.00\n",
            "DiseaseSpread       0.00\n",
            "Transmission        0.00\n",
            "SocialDist          0.00\n",
            "dtype: float64\n",
            "Filling null values with 0\n",
            "Adding time based embeddings.\n",
            "Writing total data to ../2022_Aug_target_cleaned/Total.csv\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# if you have already created the total df one, and now just want to \n",
        "# reuse it to create different population or rurality cut\n",
        "if args.cachePath:\n",
        "    total_df = pd.read_csv(args.cachePath)\n",
        "else:\n",
        "    total_df = dataMerger.get_all_features()\n",
        "    \n",
        "    output_path_total = os.path.join(args.outputPath, 'Total.csv') \n",
        "    print(f'Writing total data to {output_path_total}\\n')\n",
        "\n",
        "    # rounding up to reduce the file size\n",
        "    total_df.round(4).to_csv(output_path_total, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGPpSPbM9Hoo"
      },
      "source": [
        "## Population cut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xiq0UbD9Hoo",
        "outputId": "22d626ea-bde1-4cf9-aa54-47ae3f217a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Slicing based on top 500 counties by population\n",
            "Writing population cut data to ../2022_Aug_target_cleaned/Top_500.csv\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# you can define 'Population cut' in 'data'->'support'\n",
        "# this means how many of top counties you want to keep\n",
        "\n",
        "if dataMerger.need_population_cut():\n",
        "    population_cuts = dataMerger.population_cut(total_df)\n",
        "    for index, population_cut in enumerate(population_cuts):\n",
        "        top_counties = dataMerger.data_config.population_cut[index]\n",
        "        filename = f\"Top_{top_counties}.csv\"\n",
        "\n",
        "        output_path_population_cut = os.path.join(args.outputPath, filename)\n",
        "\n",
        "        print(f'Writing top {top_counties} populated counties data to {output_path_population_cut}.')\n",
        "        population_cuts[index].round(4).to_csv(output_path_population_cut, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Data preparation.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
